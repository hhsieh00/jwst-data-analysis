{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f278e679",
   "metadata": {},
   "source": [
    "# JWST NIRCam row-by-row background subtraction \n",
    "\n",
    "Henry Hsieh, updated 2024-05-02\n",
    "\n",
    "- Performs mitigation of \"striped\" background structure in NIRCam data by computing row-by-row median values of data files (omitting pixels associated with sources identified by an extended source detection function from median calculations), and subtracting this median value from pixels in each row\n",
    "- Extended source detection functionality based on https://spacetelescope.github.io/jdat_notebooks/notebooks/NIRCam_photometry/NIRCam_multiband_photometry.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be39282b",
   "metadata": {},
   "source": [
    "## Import required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "285e8ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,glob\n",
    "import sys\n",
    "import time,datetime\n",
    "import numpy as np\n",
    "import statistics\n",
    "from astropy.io import fits\n",
    "from astropy.convolution import convolve\n",
    "import astropy.wcs as wcs\n",
    "import astropy.units as u\n",
    "from photutils.background import Background2D, MedianBackground\n",
    "from photutils.segmentation import (detect_sources, deblend_sources, SourceCatalog,\n",
    "                                    make_2dgaussian_kernel, SegmentationImage)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c49672d5",
   "metadata": {},
   "source": [
    "## Define function to return bandpass-specific parameters\n",
    "\n",
    "- Zero point data from reference file linked from https://jwst-docs.stsci.edu/jwst-near-infrared-camera/nircam-performance/nircam-absolute-flux-calibration-and-zeropoints#NIRCamAbsoluteFluxCalibrationandZeropoints-NRC_zeropointsZeropoints\n",
    "  - `\"jwst_1126.pmap\", delivered Sep. 14, 2023: NRC_ZPs_1126pmap.txt`<br>\n",
    "    https://jwst-docs.stsci.edu/files/182256933/224166043/1/1695068757137/NRC_ZPs_1126pmap.txt\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b00b30cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bandpass_specific_parameters_files(bandpass,base_path):    \n",
    "    if bandpass == 'F200W':\n",
    "        pix_area   = 2.23E-14 * u.sr                              #Nominal pixel area in steradians from data file header (PIXAR_SR)\n",
    "        photmjsr   = 2.055999994277954 * u.MJy/u.sr/(u.DN/u.s)    #Flux density (MJy/steradian) producing 1 cps from data file header (PHOTMJSR)\n",
    "        updated_zp = 2.056 * u.MJy/u.sr/(u.DN/u.s)                #updated 2024-01-24 from https://jwst-docs.stsci.edu/files/182256933/224166043/1/1695068757137/NRC_ZPs_1126pmap.txt\n",
    "        zp_corr    = updated_zp / photmjsr\n",
    "        gain_file  = base_path + 'jwst_nircam_gain_0090.fits'     #Gain reference file name from data file header (R_GAIN)\n",
    "    if bandpass == 'F277W':\n",
    "        pix_area   = 9.2373983996251E-14 * u.sr                   #updated 2024-01-24 from jwst_nircam_photom_0153.fits\n",
    "        photmjsr   = 0.41999998688697815 * u.MJy/u.sr/(u.DN/u.s)  #Flux density (MJy/steradian) producing 1 cps from data file header (PHOTMJSR)\n",
    "        updated_zp = 0.420 * u.MJy/u.sr/(u.DN/u.s)                #updated 2024-01-24 from https://jwst-docs.stsci.edu/files/182256933/224166043/1/1695068757137/NRC_ZPs_1126pmap.txt\n",
    "        zp_corr    = updated_zp / photmjsr\n",
    "        gain_file  = base_path + 'jwst_nircam_gain_0089.fits'     #Gain reference file name from data file header (R_GAIN)\n",
    "    return pix_area,zp_corr,gain_file\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "731f7cb4",
   "metadata": {},
   "source": [
    "## Define functions to extract image file data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b107e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_image_file_data(infile,pix_area_sr):    \n",
    "    hdu         = fits.open(infile)\n",
    "    data_MJySr  = hdu[1].data\n",
    "    data_MJy    = data_MJySr * pix_area_sr.value\n",
    "    error_MJySr = hdu[2].data\n",
    "    error_MJy   = error_MJySr * pix_area_sr.value\n",
    "    imwcs       = wcs.WCS(hdu[1].header,hdu)\n",
    "    return data_MJy,error_MJy,imwcs\n",
    "\n",
    "def show_image_size_FOV(infile,data,imwcs):\n",
    "    print('Image size for {:s}: '.format(os.path.basename(infile)),end='')\n",
    "    ny, nx = data.shape\n",
    "    pixscale = wcs.utils.proj_plane_pixel_scales(imwcs)[0] \n",
    "    pixscale *= imwcs.wcs.cunit[0].to('arcsec')\n",
    "    outline = '%d x %d pixels' % (ny, nx)\n",
    "    outline += ' = %g\" x %g\"' % (ny * pixscale, nx * pixscale)\n",
    "    outline += ' (%.2f\" / pixel)' % pixscale\n",
    "    print(outline)\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "439bdea8",
   "metadata": {},
   "source": [
    "## Define function to detect and deblend extended sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6663903a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_sources_and_deblend(data,imwcs,base_path,segm_map_filename):\n",
    "    # For detection, requiring 5 connected pixels 2-sigma above background\n",
    "\n",
    "    # Measure background and set detection threshold\n",
    "    bkg_estimator = MedianBackground()\n",
    "    bkg = Background2D(data,(50,50),filter_size=(3,3),bkg_estimator=bkg_estimator)\n",
    "    threshold = bkg.background + (2.*bkg.background_rms)\n",
    "\n",
    "    # Before detection, smooth image with Gaussian FWHM = 3 pixels\n",
    "    smooth_kernel = make_2dgaussian_kernel(3.0, size=3)\n",
    "    convolved_data = convolve(data, smooth_kernel)\n",
    "\n",
    "    # Detect and deblend\n",
    "    segm_detect = detect_sources(convolved_data,threshold,npixels=5)\n",
    "    segm_deblend = deblend_sources(convolved_data,segm_detect,npixels=5,nlevels=32,contrast=0.001)\n",
    "\n",
    "    # Save segmentation map of detected objects\n",
    "    segm_hdu = fits.PrimaryHDU(segm_deblend.data.astype(np.uint32),header=imwcs.to_header())\n",
    "    segm_hdu.writeto(base_path+segm_map_filename,overwrite=True)\n",
    "\n",
    "    return bkg,segm_deblend\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4056f099",
   "metadata": {},
   "source": [
    "## Define function to create masked data file from extended source detection map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95fb7605",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_masked_data_file(image_path_data,image_path_segm):\n",
    "    with fits.open(image_path_data) as hdu_data, fits.open(image_path_segm) as hdu_segm:\n",
    "        data              = hdu_data[1].data\n",
    "        data_hdr          = hdu_data[0].header\n",
    "        segm              = hdu_segm[0].data\n",
    "        ny_data,nx_data   = data.shape\n",
    "        data_masked = [[0 for idx in range(nx_data)] for idx in range(ny_data)]\n",
    "        for idx1 in range(nx_data):\n",
    "            for idx2 in range(ny_data):\n",
    "                if segm[idx1][idx2] == 0:\n",
    "                    data_masked[idx1][idx2] = data[idx1][idx2]\n",
    "                else:\n",
    "                    data_masked[idx1][idx2] = 0\n",
    "        image_path_masked = image_path_data[:-5]+'_masked.fits'\n",
    "        fits.writeto(image_path_masked,data_masked,data_hdr,overwrite=True,checksum=True)\n",
    "    return image_path_masked\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f21e8548",
   "metadata": {},
   "source": [
    "## Define function to perform row-by-row background subtraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa74544a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_rowbgsub_data_file(image_path_data,image_path_masked):\n",
    "    with fits.open(image_path_data) as hdu_data, fits.open(image_path_masked) as hdu_data_masked:\n",
    "        data              = hdu_data[1].data\n",
    "        data_hdr0         = hdu_data[0].header\n",
    "        data_hdr1         = hdu_data[1].header\n",
    "        data_hdr          = data_hdr0 + data_hdr1\n",
    "        data_masked       = hdu_data_masked[0].data\n",
    "        ny_data,nx_data   = data.shape\n",
    "        data_rowbgsub     = [[] for idx in range(ny_data)]\n",
    "        for idx1 in range(ny_data):\n",
    "            row_data = []\n",
    "            for idx2 in range(nx_data):\n",
    "                if data_masked[idx1][idx2] > 0:\n",
    "                    row_data.append(data[idx1][idx2])\n",
    "            if row_data != []:\n",
    "                data_rowbgsub[idx1] = data[idx1] - statistics.median(row_data)\n",
    "            else:\n",
    "                data_rowbgsub[idx1] = data[idx1]\n",
    "        image_path_rowbgsub = image_path_data[:-5]+'_rowbgsub.fits'\n",
    "        fits.writeto(image_path_rowbgsub,data_rowbgsub,data_hdr,overwrite=True,checksum=True)\n",
    "    return image_path_rowbgsub\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a45d6e03",
   "metadata": {},
   "source": [
    "## Define function to perform end-to-end background correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "956ed44a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def background_subtraction(base_path,bandpass,fits_filename_string):\n",
    "    print('Performing row-by-row median subtraction for data in {:s}...'.format(base_path))\n",
    "\n",
    "    os.chdir(base_path)\n",
    "    pix_area,zp_corr,gain_file = get_bandpass_specific_parameters_files(bandpass,base_path)\n",
    "    \n",
    "    for fits_filename in sorted(glob.glob(fits_filename_string)):\n",
    "        image_path_data = base_path + fits_filename\n",
    "        \n",
    "        print('{:s} - Extracting image data from {:s}...'.format(datetime.datetime.today().strftime('%Y-%m-%d %H:%M:%S'),image_path_data))\n",
    "        data,error,imwcs = extract_image_file_data(image_path_data,pix_area)\n",
    "        show_image_size_FOV(image_path_data,data,imwcs)\n",
    "        \n",
    "        print('{:s} - Generating deblended extended source detection map for {:s}...'.format(datetime.datetime.today().strftime('%Y-%m-%d %H:%M:%S'),image_path_data))\n",
    "        segm_map_filename = 'detections_segm_' + fits_filename\n",
    "        bkg,segm_deblend = detect_sources_and_deblend(data,imwcs,base_path,segm_map_filename)\n",
    "        \n",
    "        print('{:s} - Performing row-by-row median subtraction for {:s}...'.format(datetime.datetime.today().strftime('%Y-%m-%d %H:%M:%S'),image_path_data))\n",
    "        image_path_masked   = make_masked_data_file(image_path_data,base_path + segm_map_filename)\n",
    "        image_path_rowbgsub = make_rowbgsub_data_file(image_path_data,image_path_masked)\n",
    "\n",
    "    print('Row-by-row median subtraction complete.')\n",
    "    print('\\n{:s} output files:'.format(bandpass))\n",
    "    for processed_fits_file in sorted(glob.glob(fits_filename_string[:-5]+'_rowbgsub.fits')):\n",
    "        print(processed_fits_file)\n",
    "    print('')\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acebe931",
   "metadata": {},
   "source": [
    "## Perform end-to-end background correction for F200W and F277W observations of 358P/PANSTARRS (Program 4250)\n",
    "\n",
    "- Set base path (including trailing \"/\") to location of data files before running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed945048",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = ''\n",
    "background_subtraction(base_path,'F200W','jw04250004001_03101_0000?_nrcb1_cal.fits')\n",
    "background_subtraction(base_path,'F277W','jw04250004001_03101_0000?_nrcblong_cal.fits')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
